{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCTSC 2017 DICOM Interface example\n",
    "\n",
    "To demenostrate the use of the DICOM Interface we will use the 'Lung CT Segmentation Challenge (LCTSC)' dataset, which \n",
    "was provided as part of the AAPM challenge in 2017.\n",
    "The dataset consist of 60 cases, including computed tomography (CT) images and Radiation Therapy (RT) structure sets in DICOM format. The following structures have been delineated:\n",
    "\n",
    "- Esophagus\n",
    "- Heart\n",
    "- Left Lung\n",
    "- Right Lung\n",
    "- Spinal Cord\n",
    "\n",
    "If you would like to use the dataset for your own experiments, it can be downloaded here:\n",
    "\n",
    "https://wiki.cancerimagingarchive.net/display/Public/Lung+CT+Segmentation+Challenge+2017\n",
    "\n",
    "In our experiment, we will use 2 structures, and demonstrate how the DICOM interface can be used to load CT scans as well as segmentation masks from the DICOM images. This can be done 'on the fly' or by first reading all batches and saving them to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up tensorflow and GPUs\n",
    "\n",
    "We start by setting up tensorflow and the GPU we want to use. Here, I decided to run everything on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM interface\n",
    "\n",
    "Now, we import our newly created DICOM interface and initialize it with the path to the LCTSC dataset.\n",
    "\n",
    "The only reason this is done, is to extract information about the structures and their names contained in the dataset. \n",
    "If you already now the names of the ROI's you are interested in, you can jump to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found structures in sample : [[\"1\", 'Esophagus'], [\"2\", 'Heart'], [\"3\", 'Lung_L'], [\"4\", 'Lung_R'], [\"5\", 'SpinalCord']]\n"
     ]
    }
   ],
   "source": [
    "# Library import\n",
    "from miscnn.data_loading.interfaces.dicom_io import DICOM_interface\n",
    "\n",
    "interface = DICOM_interface()\n",
    "\n",
    "data_path = \"LCTSC/\"\n",
    "\n",
    "samples = interface.initialize(data_path)\n",
    "\n",
    "structures = interface.get_ROI_names(samples[0])\n",
    "\n",
    "print('Found structures in sample : {}'.format(structures))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that we found 5 different structures for the first sample (patient) in our dataset. \n",
    "In this example we assume that we want to build a model that performs semantic segmentation of the\n",
    "left and right lung. \n",
    "In order to tell the DICOM interface, which structures we are interested of, we simpy create a dictionary, containing the\n",
    "ROI's, as well as their class labels. The class labels are then used as the segmentation pixel values.\n",
    "\n",
    "Here we assign class: 1 to the left lung and class: 2 to the right lung. Notice that class: 0 is always used as the background class, so the dictionary should start with class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lung_L': 1, 'Lung_R': 2}\n"
     ]
    }
   ],
   "source": [
    "structure_dict = {\"Lung_L\": 1, \"Lung_R\": 2}\n",
    "\n",
    "print(structure_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the names of the ROI's and have decided which structures we want to use in our model, we simply create\n",
    "a new instance of the DICOM interface, and provide it with the structure dictionary and the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = DICOM_interface(structure_dict = structure_dict, classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection the DICOM interface to the DATA_IO class\n",
    "\n",
    "Now that we have created our DICOM interface, we simply connect it to the Data_IO class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_io = Data_IO(interface, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the interface by getting a list of all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples: ['LCTSC-Test-S1-101', 'LCTSC-Test-S1-102', 'LCTSC-Test-S1-103', 'LCTSC-Test-S1-104', 'LCTSC-Test-S1-201', 'LCTSC-Test-S1-202', 'LCTSC-Test-S1-203', 'LCTSC-Test-S1-204', 'LCTSC-Test-S2-101', 'LCTSC-Test-S2-102', 'LCTSC-Test-S2-103', 'LCTSC-Test-S2-104', 'LCTSC-Test-S2-201', 'LCTSC-Test-S2-202', 'LCTSC-Test-S2-203', 'LCTSC-Test-S2-204', 'LCTSC-Test-S3-101', 'LCTSC-Test-S3-102', 'LCTSC-Test-S3-103', 'LCTSC-Test-S3-104', 'LCTSC-Test-S3-201', 'LCTSC-Test-S3-202', 'LCTSC-Test-S3-203', 'LCTSC-Test-S3-204', 'LCTSC-Train-S1-001', 'LCTSC-Train-S1-002', 'LCTSC-Train-S1-003', 'LCTSC-Train-S1-004', 'LCTSC-Train-S1-005', 'LCTSC-Train-S1-006', 'LCTSC-Train-S1-007', 'LCTSC-Train-S1-008', 'LCTSC-Train-S1-009', 'LCTSC-Train-S1-010', 'LCTSC-Train-S1-011', 'LCTSC-Train-S1-012', 'LCTSC-Train-S2-001', 'LCTSC-Train-S2-002', 'LCTSC-Train-S2-003', 'LCTSC-Train-S2-004', 'LCTSC-Train-S2-005', 'LCTSC-Train-S2-006', 'LCTSC-Train-S2-007', 'LCTSC-Train-S2-008', 'LCTSC-Train-S2-009', 'LCTSC-Train-S2-010', 'LCTSC-Train-S2-011', 'LCTSC-Train-S2-012', 'LCTSC-Train-S3-001', 'LCTSC-Train-S3-002', 'LCTSC-Train-S3-003', 'LCTSC-Train-S3-004', 'LCTSC-Train-S3-005', 'LCTSC-Train-S3-006', 'LCTSC-Train-S3-007', 'LCTSC-Train-S3-008', 'LCTSC-Train-S3-009', 'LCTSC-Train-S3-010', 'LCTSC-Train-S3-011', 'LCTSC-Train-S3-012']\n"
     ]
    }
   ],
   "source": [
    "sample_list = data_io.get_indiceslist()\n",
    "sample_list.sort()\n",
    "print(\"All samples: \" + str(sample_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Like described in the Kidney segmentation example, we can set up a data augmentation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "from miscnn.processing.data_augmentation import Data_Augmentation\n",
    "\n",
    "# Create and configure the Data Augmentation class\n",
    "data_aug = Data_Augmentation(cycles=2, scaling=True, rotations=True, elastic_deform=True, mirror=True,\n",
    "                             brightness=True, contrast=True, gamma=True, gaussian_noise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose preprocessing functions\n",
    "\n",
    "Now we set up some preprocssing functions. We first normalize the images, resample the scans to same voxel size and clip values that fall out of a certain range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miscnn.processing.subfunctions.normalization import Normalization\n",
    "from miscnn.processing.subfunctions.clipping import Clipping\n",
    "from miscnn.processing.subfunctions.resampling import Resampling\n",
    "\n",
    "# Create a pixel value normalization Subfunction through Z-Score \n",
    "sf_normalize = Normalization()\n",
    "\n",
    "sf_resample = Resampling((3.22, 1.62, 1.62))\n",
    "# Create a clipping Subfunction between -79 and 304\n",
    "sf_clipping = Clipping(min=-79, max=304)\n",
    "# Create a resampling Subfunction to voxel spacing 3.22 x 1.62 x 1.62\n",
    "# Assemble Subfunction classes into a list\n",
    "# Be aware that the Subfunctions will be exectued according to the list order!\n",
    "subfunctions = [sf_resample, sf_clipping, sf_normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create our Preprocessor and decide how we would like to train our network (full image or patch wise). In this case we use the patchwise-crop analysis, where we randomly crop patches of size (80, 160, 160) from our CT volumes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "from miscnn.processing.preprocessor import Preprocessor\n",
    "\n",
    "# Create and configure the Preprocessor class\n",
    "pp = Preprocessor(data_io, data_aug=data_aug, batch_size=2, subfunctions=subfunctions, prepare_subfunctions=False, \n",
    "                  prepare_batches=True, analysis=\"patchwise-crop\", patch_shape=(80, 160, 160))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "\n",
    "Finally we decide which neural network archictecture we want to use, which loss function we want to optimize and which metrics we want to use as a performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [] and type float\n\t [[node conv3d_34/kernel/Initializer/random_uniform/min (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'conv3d_34/kernel/Initializer/random_uniform/min':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n    yield self.process_one()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-f4ecc462df9f>\", line 7, in <module>\n    batch_queue_size=5, workers=8, learninig_rate=0.0001, gpu_number=1)\n  File \"/mnt/md1/Micha/Projects/MIScnn/miscnn/neural_network/model.py\", line 73, in __init__\n    n_labels=self.classes)\n  File \"/mnt/md1/Micha/Projects/MIScnn/miscnn/neural_network/architecture/unet/standard.py\", line 132, in create_model_3D\n    self.ba_norm_momentum)\n  File \"/mnt/md1/Micha/Projects/MIScnn/miscnn/neural_network/architecture/unet/standard.py\", line 200, in expanding_layer_3D\n    conv2 = Conv3D(neurons, (3, 3, 3), activation='relu', padding='same')(conv1)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 824, in __call__\n    self._maybe_build(inputs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2146, in _maybe_build\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 165, in build\n    dtype=self.dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 529, in add_weight\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\", line 712, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 139, in make_variable\n    shape=variable_shape if variable_shape else None)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\", line 2503, in default_variable_creator\n    shape=shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1406, in __init__\n    distribute_strategy=distribute_strategy)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1537, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 119, in <lambda>\n    init_val = lambda: initializer(shape, dtype=dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py\", line 533, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/random_ops.py\", line 238, in random_uniform\n    minval = ops.convert_to_tensor(minval, dtype=dtype, name=\"min\")\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1184, in convert_to_tensor\n    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1242, in convert_to_tensor_v2\n    as_ref=False)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1297, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n    return constant_op.constant(value, dtype, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 227, in constant\n    allow_broadcast=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 271, in _constant_impl\n    name=name).outputs[0]\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [] and type float\n\t [[{{node conv3d_34/kernel/Initializer/random_uniform/min}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f4ecc462df9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create the Neural Network model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m model = Neural_Network(preprocessor=pp, loss=tversky_loss, metrics=[dice_soft, dice_crossentropy],\n\u001b[0;32m----> 7\u001b[0;31m                        batch_queue_size=5, workers=8, learninig_rate=0.0001, gpu_number=1)\n\u001b[0m",
      "\u001b[0;32m/mnt/md1/Micha/Projects/MIScnn/miscnn/neural_network/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, preprocessor, architecture, loss, metrics, learninig_rate, batch_queue_size, workers, gpu_number)\u001b[0m\n\u001b[1;32m     84\u001b[0m                            loss=loss, metrics=metrics)\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Cache starting weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialization_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Cache parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \"\"\"\n\u001b[1;32m   1351\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_updates_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   3183\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3184\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3186\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3187\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [] and type float\n\t [[node conv3d_34/kernel/Initializer/random_uniform/min (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'conv3d_34/kernel/Initializer/random_uniform/min':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n    yield self.process_one()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/mluser1/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-f4ecc462df9f>\", line 7, in <module>\n    batch_queue_size=5, workers=8, learninig_rate=0.0001, gpu_number=1)\n  File \"/mnt/md1/Micha/Projects/MIScnn/miscnn/neural_network/model.py\", line 73, in __init__\n    n_labels=self.classes)\n  File \"/mnt/md1/Micha/Projects/MIScnn/miscnn/neural_network/architecture/unet/standard.py\", line 132, in create_model_3D\n    self.ba_norm_momentum)\n  File \"/mnt/md1/Micha/Projects/MIScnn/miscnn/neural_network/architecture/unet/standard.py\", line 200, in expanding_layer_3D\n    conv2 = Conv3D(neurons, (3, 3, 3), activation='relu', padding='same')(conv1)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 824, in __call__\n    self._maybe_build(inputs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2146, in _maybe_build\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 165, in build\n    dtype=self.dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 529, in add_weight\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\", line 712, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 139, in make_variable\n    shape=variable_shape if variable_shape else None)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\", line 2503, in default_variable_creator\n    shape=shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1406, in __init__\n    distribute_strategy=distribute_strategy)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1537, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 119, in <lambda>\n    init_val = lambda: initializer(shape, dtype=dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py\", line 533, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/random_ops.py\", line 238, in random_uniform\n    minval = ops.convert_to_tensor(minval, dtype=dtype, name=\"min\")\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1184, in convert_to_tensor\n    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1242, in convert_to_tensor_v2\n    as_ref=False)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1297, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n    return constant_op.constant(value, dtype, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 227, in constant\n    allow_broadcast=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 271, in _constant_impl\n    name=name).outputs[0]\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Library import\n",
    "from miscnn.neural_network.model import Neural_Network\n",
    "from miscnn.neural_network.metrics import dice_soft, dice_crossentropy, tversky_loss\n",
    "\n",
    "# Create the Neural Network model\n",
    "model = Neural_Network(preprocessor=pp, loss=tversky_loss, metrics=[dice_soft, dice_crossentropy],\n",
    "                       batch_queue_size=3, workers=3, learninig_rate=0.0001, gpu_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miscnn.evaluation import split_validation\n",
    "\n",
    "split_validation(sample_list, model,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
