{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCTSC 2017 DICOM Interface example\n",
    "\n",
    "To demenostrate the use of the DICOM Interface we will use the 'Lung CT Segmentation Challenge (LCTSC)' dataset, which \n",
    "was provided as part of the AAPM challenge in 2017.\n",
    "The dataset consist of 60 cases, including computed tomography (CT) images and Radiation Therapy (RT) structure sets in DICOM format. The following structures have been delineated:\n",
    "\n",
    "- Esophagus\n",
    "- Heart\n",
    "- Left Lung\n",
    "- Right Lung\n",
    "- Spinal Cord\n",
    "\n",
    "If you would like to use the dataset for your own experiments, it can be downloaded here:\n",
    "\n",
    "https://wiki.cancerimagingarchive.net/display/Public/Lung+CT+Segmentation+Challenge+2017\n",
    "\n",
    "In our experiment, we will use 2 structures, and demonstrate how the DICOM interface can be used to load CT scans as well as segmentation masks from the DICOM images. This can be done 'on the fly' or by first reading all batches and saving them to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up tensorflow and GPUs\n",
    "\n",
    "We start by setting up tensorflow and the GPU we want to use. Here, I decided to run everything on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1, 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM interface\n",
    "\n",
    "Now, we import our newly created DICOM interface and initialize it with the path to the LCTSC dataset.\n",
    "\n",
    "The only reason this is done, is to extract information about the structures and their names contained in the dataset. \n",
    "If you already now the names of the ROI's you are interested in, you can jump to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found structures in sample : [[\"1\", 'Esophagus'], [\"2\", 'Heart'], [\"3\", 'Lung_L'], [\"4\", 'Lung_R'], [\"5\", 'SpinalCord']]\n"
     ]
    }
   ],
   "source": [
    "# Library import\n",
    "from miscnn.data_loading.interfaces.dicom_io import DICOM_interface\n",
    "\n",
    "interface = DICOM_interface()\n",
    "\n",
    "data_path = \"LCTSC/\"\n",
    "\n",
    "samples = interface.initialize(data_path)\n",
    "\n",
    "structures = interface.get_ROI_names(samples[0])\n",
    "\n",
    "print('Found structures in sample : {}'.format(structures))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that we found 5 different structures for the first sample (patient) in our dataset. \n",
    "In this example we assume that we want to build a model that performs semantic segmentation of the\n",
    "left and right lung. \n",
    "In order to tell the DICOM interface, which structures we are interested of, we simpy create a dictionary, containing the\n",
    "ROI's, as well as their class labels. The class labels are then used as the segmentation pixel values.\n",
    "\n",
    "Here we assign class: 1 to the left lung and class: 2 to the right lung. Notice that class: 0 is always used as the background class, so the dictionary should start with class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lung_L': 1, 'Lung_R': 2}\n"
     ]
    }
   ],
   "source": [
    "structure_dict = {\"Lung_L\": 1, \"Lung_R\": 2}\n",
    "\n",
    "print(structure_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the names of the ROI's and have decided which structures we want to use in our model, we simply create\n",
    "a new instance of the DICOM interface, and provide it with the structure dictionary and the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = DICOM_interface(structure_dict = structure_dict, classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection the DICOM interface to the DATA_IO class\n",
    "\n",
    "Now that we have created our DICOM interface, we simply connect it to the Data_IO class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miscnn.data_loading.data_io import Data_IO\n",
    "\n",
    "data_io = Data_IO(interface, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the interface by getting a list of all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples: ['LCTSC-Test-S1-101', 'LCTSC-Test-S1-102', 'LCTSC-Test-S1-103', 'LCTSC-Test-S1-104', 'LCTSC-Test-S1-201', 'LCTSC-Test-S1-202', 'LCTSC-Test-S1-203', 'LCTSC-Test-S1-204', 'LCTSC-Test-S2-101', 'LCTSC-Test-S2-102', 'LCTSC-Test-S2-103', 'LCTSC-Test-S2-104', 'LCTSC-Test-S2-201', 'LCTSC-Test-S2-202', 'LCTSC-Test-S2-203', 'LCTSC-Test-S2-204', 'LCTSC-Test-S3-101', 'LCTSC-Test-S3-102', 'LCTSC-Test-S3-103', 'LCTSC-Test-S3-104', 'LCTSC-Test-S3-201', 'LCTSC-Test-S3-202', 'LCTSC-Test-S3-203', 'LCTSC-Test-S3-204', 'LCTSC-Train-S1-001', 'LCTSC-Train-S1-002', 'LCTSC-Train-S1-003', 'LCTSC-Train-S1-004', 'LCTSC-Train-S1-005', 'LCTSC-Train-S1-006', 'LCTSC-Train-S1-007', 'LCTSC-Train-S1-008', 'LCTSC-Train-S1-009', 'LCTSC-Train-S1-010', 'LCTSC-Train-S1-011', 'LCTSC-Train-S1-012', 'LCTSC-Train-S2-001', 'LCTSC-Train-S2-002', 'LCTSC-Train-S2-003', 'LCTSC-Train-S2-004', 'LCTSC-Train-S2-005', 'LCTSC-Train-S2-006', 'LCTSC-Train-S2-007', 'LCTSC-Train-S2-008', 'LCTSC-Train-S2-009', 'LCTSC-Train-S2-010', 'LCTSC-Train-S2-011', 'LCTSC-Train-S2-012', 'LCTSC-Train-S3-001', 'LCTSC-Train-S3-002', 'LCTSC-Train-S3-003', 'LCTSC-Train-S3-004', 'LCTSC-Train-S3-005', 'LCTSC-Train-S3-006', 'LCTSC-Train-S3-007', 'LCTSC-Train-S3-008', 'LCTSC-Train-S3-009', 'LCTSC-Train-S3-010', 'LCTSC-Train-S3-011', 'LCTSC-Train-S3-012']\n"
     ]
    }
   ],
   "source": [
    "sample_list = data_io.get_indiceslist()\n",
    "sample_list.sort()\n",
    "print(\"All samples: \" + str(sample_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Like described in the Kidney segmentation example, we can set up a data augmentation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "from miscnn.processing.data_augmentation import Data_Augmentation\n",
    "\n",
    "# Create and configure the Data Augmentation class\n",
    "data_aug = Data_Augmentation(cycles=2, scaling=True, rotations=True, elastic_deform=True, mirror=True,\n",
    "                             brightness=True, contrast=True, gamma=True, gaussian_noise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose preprocessing functions\n",
    "\n",
    "Now we set up some preprocssing functions. We first normalize the images, resample the scans to same voxel size and clip values that fall out of a certain range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miscnn.processing.subfunctions.normalization import Normalization\n",
    "from miscnn.processing.subfunctions.clipping import Clipping\n",
    "from miscnn.processing.subfunctions.resampling import Resampling\n",
    "\n",
    "# Create a pixel value normalization Subfunction through Z-Score \n",
    "sf_normalize = Normalization()\n",
    "\n",
    "sf_resample = Resampling((3.22, 1.62, 1.62))\n",
    "# Create a clipping Subfunction between -79 and 304\n",
    "sf_clipping = Clipping(min=-79, max=304)\n",
    "# Create a resampling Subfunction to voxel spacing 3.22 x 1.62 x 1.62\n",
    "# Assemble Subfunction classes into a list\n",
    "# Be aware that the Subfunctions will be exectued according to the list order!\n",
    "subfunctions = [sf_resample, sf_clipping, sf_normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create our Preprocessor and decide how we would like to train our network (full image or patch wise). In this case we use the patchwise-crop analysis, where we randomly crop patches of size (80, 160, 160) from our CT volumes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "from miscnn.processing.preprocessor import Preprocessor\n",
    "\n",
    "# Create and configure the Preprocessor class\n",
    "pp = Preprocessor(data_io, data_aug=data_aug, batch_size=2, subfunctions=subfunctions, prepare_subfunctions=False, \n",
    "                  prepare_batches=True, analysis=\"patchwise-crop\", patch_shape=(80, 160, 160))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "\n",
    "Finally we decide which neural network archictecture we want to use, which loss function we want to optimize and which metrics we want to use as a performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Library import\n",
    "from miscnn.neural_network.model import Neural_Network\n",
    "from miscnn.neural_network.metrics import dice_soft, dice_crossentropy, tversky_loss\n",
    "\n",
    "# Create the Neural Network model\n",
    "model = Neural_Network(preprocessor=pp, loss=tversky_loss, metrics=[dice_soft, dice_crossentropy],\n",
    "                       batch_queue_size=3, workers=3, learninig_rate=0.0001, gpu_number=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9bcf61d34572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmiscnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplit_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msplit_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/md1/Micha/Projects/MIScnn/miscnn/evaluation/split_validation.py\u001b[0m in \u001b[0;36msplit_validation\u001b[0;34m(sample_list, model, percentage, epochs, iterations, evaluation_path, draw_figures, run_detailed_evaluation, callbacks, direct_output)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Run training & validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     history = model.evaluate(training, validation, epochs=epochs,\n\u001b[0;32m---> 69\u001b[0;31m                              iterations=iterations, callbacks=callbacks)\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Initialize evaluation directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcreate_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/Micha/Projects/MIScnn/miscnn/neural_network/model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, training_samples, validation_samples, epochs, iterations, callbacks)\u001b[0m\n\u001b[1;32m    187\u001b[0m                                          \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                                          \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                                          iterations=iterations)\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# Initialize a Keras Data Generator for generating Validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         dataGen_validation = DataGenerator(validation_samples,\n",
      "\u001b[0;32m/mnt/md1/Micha/Projects/MIScnn/miscnn/neural_network/data_generator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sample_list, preprocessor, training, validation, shuffle, iterations)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# If batches should be prepared before runtime -> do it now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mbatches_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchpointers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/Micha/Projects/MIScnn/miscnn/processing/preprocessor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, indices_list, training, validation)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# Load sample and process provided subfunctions on image data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_subfunctions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_seg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubfunctions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/Micha/Projects/MIScnn/miscnn/data_loading/data_io.py\u001b[0m in \u001b[0;36msample_loader\u001b[0;34m(self, index, load_seg, load_pred, backup)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# IF needed read the provided segmentation for current sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload_seg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0msegmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# IF needed read the provided prediction for current sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/Micha/Projects/MIScnn/miscnn/data_loading/interfaces/dicom_io.py\u001b[0m in \u001b[0;36mload_segmentation\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image_sitk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0msegmentations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/Micha/Projects/MIScnn/miscnn/data_loading/interfaces/dicom_io.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, rtstruct_contours, dicom_image)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                     \u001b[0mfilled_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poly2mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                     \u001b[0mnp_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled_poly\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructure_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrtstruct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ROI_Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sitk is xyz, numpy is zyx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                     \u001b[0;31m#mask = sitk.GetImageFromArray(np_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md1/Micha/Projects/MIScnn/miscnn/data_loading/interfaces/dicom_io.py\u001b[0m in \u001b[0;36m_poly2mask\u001b[0;34m(self, coords_x, coords_y, shape)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poly2mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mfill_coords_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_coords_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfill_coords_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_coords_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m# sitk is xyz, numpy is zyx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skimage/draw/draw.py\u001b[0m in \u001b[0;36mpolygon\u001b[0;34m(r, c, shape)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \"\"\"\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_polygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from miscnn.evaluation import split_validation\n",
    "\n",
    "split_validation(sample_list, model,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
