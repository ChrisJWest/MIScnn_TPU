{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCTSC 2017 DICOM Interface example\n",
    "\n",
    "To demenostrate the use of the DICOM Interface we will use the 'Lung CT Segmentation Challenge (LCTSC)' dataset, which \n",
    "was provided as part of the AAPM challenge in 2017.\n",
    "The dataset consist of 60 cases, including computed tomography (CT) images and Radiation Therapy (RT) structure sets in DICOM format. The following structures have been delineated:\n",
    "\n",
    "- Esophagus\n",
    "- Heart\n",
    "- Left Lung\n",
    "- Right Lung\n",
    "- Spinal Cord\n",
    "\n",
    "If you would like to use the dataset for your own experiments, it can be downloaded here:\n",
    "\n",
    "https://wiki.cancerimagingarchive.net/display/Public/Lung+CT+Segmentation+Challenge+2017\n",
    "\n",
    "In our experiment, we will use 2 structures, and demonstrate how the DICOM interface can be used to load CT scans as well as segmentation masks from the DICOM images. This can be done 'on the fly' or by first reading all batches and saving them to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up tensorflow and GPUs\n",
    "\n",
    "We start by setting up tensorflow and the GPU we want to use. Here, I decided to run everything on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1, 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM interface\n",
    "\n",
    "Now, we import our newly created DICOM interface and initialize it with the path to the LCTSC dataset.\n",
    "\n",
    "The only reason this is done, is to extract information about the structures and their names contained in the dataset. \n",
    "If you already now the names of the ROI's you are interested in, you can jump to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found structures in sample : [[\"1\", 'Esophagus'], [\"2\", 'Heart'], [\"3\", 'Lung_L'], [\"4\", 'Lung_R'], [\"5\", 'SpinalCord']]\n"
     ]
    }
   ],
   "source": [
    "# Library import\n",
    "from miscnn.data_loading.interfaces.dicom_io import DICOM_interface\n",
    "\n",
    "interface = DICOM_interface()\n",
    "\n",
    "data_path = \"LCTSC/\"\n",
    "\n",
    "samples = interface.initialize(data_path)\n",
    "\n",
    "structures = interface.get_ROI_names(samples[0])\n",
    "\n",
    "print('Found structures in sample : {}'.format(structures))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that we found 5 different structures for the first sample (patient) in our dataset. \n",
    "In this example we assume that we want to build a model that performs semantic segmentation of the\n",
    "left and right lung. \n",
    "In order to tell the DICOM interface, which structures we are interested of, we simpy create a dictionary, containing the\n",
    "ROI's, as well as their class labels. The class labels are then used as the segmentation pixel values.\n",
    "\n",
    "Here we assign class: 1 to the left lung and class: 2 to the right lung. Notice that class: 0 is always used as the background class, so the dictionary should start with class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lung_L': 1, 'Lung_R': 2}\n"
     ]
    }
   ],
   "source": [
    "structure_dict = {\"Lung_L\": 1, \"Lung_R\": 2}\n",
    "\n",
    "print(structure_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the names of the ROI's and have decided which structures we want to use in our model, we simply create\n",
    "a new instance of the DICOM interface, and provide it with the structure dictionary and the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = DICOM_interface(structure_dict = structure_dict, classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection the DICOM interface to the DATA_IO class\n",
    "\n",
    "Now that we have created our DICOM interface, we simply connect it to the Data_IO class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miscnn.data_loading.data_io import Data_IO\n",
    "\n",
    "data_io = Data_IO(interface, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the interface by getting a list of all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples: ['LCTSC-Test-S1-101', 'LCTSC-Test-S1-102', 'LCTSC-Test-S1-103', 'LCTSC-Test-S1-104', 'LCTSC-Test-S1-201', 'LCTSC-Test-S1-202', 'LCTSC-Test-S1-203', 'LCTSC-Test-S1-204', 'LCTSC-Test-S2-101', 'LCTSC-Test-S2-102', 'LCTSC-Test-S2-103', 'LCTSC-Test-S2-104', 'LCTSC-Test-S2-201', 'LCTSC-Test-S2-202', 'LCTSC-Test-S2-203', 'LCTSC-Test-S2-204', 'LCTSC-Test-S3-101', 'LCTSC-Test-S3-102', 'LCTSC-Test-S3-103', 'LCTSC-Test-S3-104', 'LCTSC-Test-S3-201', 'LCTSC-Test-S3-202', 'LCTSC-Test-S3-203', 'LCTSC-Test-S3-204', 'LCTSC-Train-S1-001', 'LCTSC-Train-S1-002', 'LCTSC-Train-S1-003', 'LCTSC-Train-S1-004', 'LCTSC-Train-S1-005', 'LCTSC-Train-S1-006', 'LCTSC-Train-S1-007', 'LCTSC-Train-S1-008', 'LCTSC-Train-S1-009', 'LCTSC-Train-S1-010', 'LCTSC-Train-S1-011', 'LCTSC-Train-S1-012', 'LCTSC-Train-S2-001', 'LCTSC-Train-S2-002', 'LCTSC-Train-S2-003', 'LCTSC-Train-S2-004', 'LCTSC-Train-S2-005', 'LCTSC-Train-S2-006', 'LCTSC-Train-S2-007', 'LCTSC-Train-S2-008', 'LCTSC-Train-S2-009', 'LCTSC-Train-S2-010', 'LCTSC-Train-S2-011', 'LCTSC-Train-S2-012', 'LCTSC-Train-S3-001', 'LCTSC-Train-S3-002', 'LCTSC-Train-S3-003', 'LCTSC-Train-S3-004', 'LCTSC-Train-S3-005', 'LCTSC-Train-S3-006', 'LCTSC-Train-S3-007', 'LCTSC-Train-S3-008', 'LCTSC-Train-S3-009', 'LCTSC-Train-S3-010', 'LCTSC-Train-S3-011', 'LCTSC-Train-S3-012']\n"
     ]
    }
   ],
   "source": [
    "sample_list = data_io.get_indiceslist()\n",
    "sample_list.sort()\n",
    "print(\"All samples: \" + str(sample_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Like described in the Kidney segmentation example, we can set up a data augmentation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "from miscnn.processing.data_augmentation import Data_Augmentation\n",
    "\n",
    "# Create and configure the Data Augmentation class\n",
    "data_aug = Data_Augmentation(cycles=2, scaling=True, rotations=True, elastic_deform=True, mirror=True,\n",
    "                             brightness=True, contrast=True, gamma=True, gaussian_noise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose preprocessing functions\n",
    "\n",
    "Now we set up some preprocssing functions. We first normalize the images, resample the scans to same voxel size and clip values that fall out of a certain range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miscnn.processing.subfunctions.normalization import Normalization\n",
    "from miscnn.processing.subfunctions.clipping import Clipping\n",
    "from miscnn.processing.subfunctions.resampling import Resampling\n",
    "\n",
    "# Create a pixel value normalization Subfunction through Z-Score \n",
    "sf_normalize = Normalization()\n",
    "\n",
    "sf_resample = Resampling((3.22, 1.62, 1.62))\n",
    "# Create a clipping Subfunction between -79 and 304\n",
    "sf_clipping = Clipping(min=-79, max=304)\n",
    "# Create a resampling Subfunction to voxel spacing 3.22 x 1.62 x 1.62\n",
    "# Assemble Subfunction classes into a list\n",
    "# Be aware that the Subfunctions will be exectued according to the list order!\n",
    "subfunctions = [sf_resample, sf_clipping, sf_normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create our Preprocessor and decide how we would like to train our network (full image or patch wise). In this case we use the patchwise-crop analysis, where we randomly crop patches of size (80, 160, 160) from our CT volumes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "from miscnn.processing.preprocessor import Preprocessor\n",
    "\n",
    "# Create and configure the Preprocessor class\n",
    "pp = Preprocessor(data_io, data_aug=data_aug, batch_size=2, subfunctions=subfunctions, prepare_subfunctions=False, \n",
    "                  prepare_batches=True, analysis=\"patchwise-crop\", patch_shape=(80, 160, 160))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "\n",
    "Finally we decide which neural network archictecture we want to use, which loss function we want to optimize and which metrics we want to use as a performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "from miscnn.neural_network.model import Neural_Network\n",
    "from miscnn.neural_network.metrics import dice_soft, dice_crossentropy, tversky_loss\n",
    "\n",
    "# Create the Neural Network model\n",
    "model = Neural_Network(preprocessor=pp, loss=tversky_loss, metrics=[dice_soft, dice_crossentropy],\n",
    "                       batch_queue_size=3, workers=3, learninig_rate=0.0001, gpu_number=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the network is build and compiled, we can start training, like i.ex. by simply splitting our sample list into a training and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miscnn.evaluation import split_validation\n",
    "\n",
    "split_validation(sample_list, model,epochs = 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
